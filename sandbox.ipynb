{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sys\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsedit_notes_helpers import get_diff_data, summarize_edits, get_bm_edits, get_wm_edits, get_cp_edits, get_bfs_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnum = 'CC0117_core1'\n",
    "typ = 'bm'\n",
    "basedir='/Users/zeynepenkavi/Downloads/ConteQC'\n",
    "outdir='/Users/zeynepenkavi/Downloads/ConteQC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "editp = path.join(basedir, 'sub-'+subnum)\n",
    "uneditp = path.join(basedir, 'sub-'+subnum+'_unedited')\n",
    "typ_dict = {'bm': 'brainmask', 'wm': 'wm', 'bfs': 'brain.finalsurfs', 'cp': 'control.dat'}\n",
    "vol = typ_dict[typ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists = path.isfile(path.join(basedir, 'sub-'+subnum+'.zip'))\n",
    "if not exists:\n",
    "    print(\"Unedited images not found in directory. Quitting...\")\n",
    "    try:\n",
    "        sys.exit()\n",
    "    except SystemExit:\n",
    "        print(\"Quit because difference images cannot be calculated without unedited images.\")\n",
    "else:\n",
    "    # Unzip unedited images of potential interest\n",
    "    toExtract = ['brainmask.mgz', 'wm.mgz', 'brain.finalsurfs.mgz']\n",
    "    suffix = path.join('sub-'+subnum, 'mri')\n",
    "    toExtract = [path.join(suffix, s) for s in toExtract]\n",
    "    with ZipFile(path.join(basedir, 'sub-'+subnum+'.zip'), 'r') as zipObj:\n",
    "        # Get a list of all archived file names from the zip\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        # Iterate over the file names\n",
    "        for fileName in listOfFileNames:\n",
    "            # Check filename endswith csv\n",
    "            if fileName in toExtract:\n",
    "                # Extract a single file from zip\n",
    "                zipObj.extract(fileName, path.join(basedir, 'sub-'+subnum+'_unedited'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>min_sag</th>\n",
       "      <th>max_sag</th>\n",
       "      <th>min_axe</th>\n",
       "      <th>max_axe</th>\n",
       "      <th>min_cor</th>\n",
       "      <th>max_cor</th>\n",
       "      <th>num_vox</th>\n",
       "      <th>vol</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>134</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>wm</td>\n",
       "      <td>add voxel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>wm</td>\n",
       "      <td>delete voxel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  min_sag  max_sag  min_axe  max_axe  min_cor  max_cor  num_vox vol  \\\n",
       "0       -1      110      112      134      136      137      137        4  wm   \n",
       "0       -1      111      112      135      136      137      137        4  wm   \n",
       "\n",
       "         action  \n",
       "0     add voxel  \n",
       "0  delete voxel  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typ = \"wm\"\n",
    "vol = typ_dict[typ]\n",
    "get_wm_edits(editp, uneditp, vol, subnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_diff_data(editp, uneditp, vol, subnum)\n",
    "cur_diff_data = tmp.query(\"Action=='add voxel'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_diff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = distance_matrix(cur_diff_data.loc[:,('Sag', 'Axe', 'Cor')], cur_diff_data.loc[:,('Sag', 'Axe', 'Cor')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=50, min_samples=5).fit(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_diff_data['cluster'] = list(clustering.labels_)\n",
    "cur_diff_data.insert(0, \"cluster\", list(clustering.labels_), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_diff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_edits(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bm_edits(editp, uneditp, vol, subnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = \"cp\"\n",
    "vol = typ_dict[typ]\n",
    "get_cp_edits(editp, uneditp, vol, subnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = \"bfs\"\n",
    "vol = typ_dict[typ]\n",
    "get_bfs_edits(editp, uneditp, vol, subnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_dict = {'bm': get_bm_edits, 'wm': get_wm_edits, 'cp': get_cp_edits, 'bfs': get_bfs_edits}\n",
    "typ = \"all\"\n",
    "if typ == 'all':\n",
    "    out = pd.DataFrame()\n",
    "    # loop through function lookup dictionary and run all edit extraction functions\n",
    "    for k,v in fn_dict.items():\n",
    "        vol = typ_dict[k]\n",
    "        out = out.append(v(editp=editp, uneditp=uneditp, vol=vol, subnum=subnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do still: \n",
    "\n",
    "how will this be used? \n",
    "no notes taken while editing\n",
    "run this for subject after editing to get notes\n",
    "[present output in slack channel before switching to this fully]\n",
    "\n",
    "next step i need to do: \n",
    "refine previous edits\n",
    "\n",
    "can this be useful for that?\n",
    "could at least run all subjects through this and see if i've missed writing down any edits i've made\n",
    "\n",
    "how should i go about refining edits?\n",
    "go over mike's reports and compare for each subject how different i am from dorit/mike\n",
    "run their edited images (taken from box) through \n",
    "\n",
    "so timeline:\n",
    "finish this script\n",
    "    -go over current output and see if it misses anything for bm\n",
    "    -write other volume edits extractions\n",
    "run all subjects through this and see if you've missed recording any edits\n",
    "move onto refinement of previous edits:\n",
    "    -download dorit's edits from box and make difference images for \n",
    "    -overlay original, my edits difference image, dorit's difference image in freeview and scroll through\n",
    "move onto editing new subjects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
